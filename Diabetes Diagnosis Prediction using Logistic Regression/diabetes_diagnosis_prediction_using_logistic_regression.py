# -*- coding: utf-8 -*-
"""Diabetes Diagnosis Prediction using Logistic Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W8aUL-8gWyORNedXJQCQV0yJr4WnTvTm

This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage

The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.

# Libraries to Be Used
Numpy -
Pandas -
Scikit-Learn -
MatPlotLib -
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import SimpleImputer
from sklearn.feature_selection import SelectKBest, f_classif

df = pd.read_csv('diabetes.csv')

df.head()

df.shape

"""Dependent Variable is categorical thus Logistic Regression will be used."""

# Select only the columns with invalid zeros
cols = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]
# Replace 0 with NaN first (so the imputer treats them as missing)
df[cols] = df[cols].replace(0, np.nan)

# Apply median imputation
imputer = SimpleImputer(strategy='median')
df[cols] = imputer.fit_transform(df[cols])

df.describe()

df.isna().sum() #How many missing values

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report

model = LogisticRegression()

x = df.drop('Outcome',axis=1)
y = df['Outcome']
x.head()

y.head()

from sklearn.preprocessing import MinMaxScaler
Preprocessed_df = MinMaxScaler().fit_transform(x)

Preprocessed_df = pd.DataFrame(Preprocessed_df,columns=x.columns)
Preprocessed_df.head()

Preprocessed_df.describe()

selector = SelectKBest(f_classif, k=5)
selector.fit(Preprocessed_df, y)

selectedFeatures = Preprocessed_df.columns[selector.get_support()]
print(selectedFeatures)

X_train, X_test, y_train, y_test = train_test_split(Preprocessed_df, y, train_size=0.8, random_state=42)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

model.score(X_test,y_test)

from sklearn.metrics import confusion_matrix, roc_curve
from sklearn.metrics import classification_report
print(confusion_matrix(y_test,y_pred))

# Plot heatmap
plt.figure(figsize=(6,4))
sns.heatmap(confusion_matrix(y_test,y_pred), annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Predicted 0 (No Diabetes)', 'Predicted 1 (Diabetes)'],
            yticklabels=['Actual 0 (No Diabetes)', 'Actual 1 (Diabetes)'])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

print(classification_report(y_test,y_pred))

from sklearn.metrics import precision_score, recall_score, f1_score

print('Precision Score:',precision_score(y_test, y_pred))
print('Recall Score:',recall_score(y_test, y_pred))
print('F1 Score:',f1_score(y_test, y_pred))

# Train your logistic regression with normalized data (X_train_norm, etc.)
model.fit(X_train, y_train)

# Get predicted probabilities instead of hard labels
y_probs = model.predict_proba(X_test)[:, 1]

# Try a custom threshold (e.g., 0.4 instead of 0.5)
threshold = 0.3
y_pred_custom = (y_probs >= threshold).astype(int)

# Evaluate
print("Confusion Matrix (threshold = 0.5):")
print(confusion_matrix(y_test, y_pred_custom))
print("\nClassification Report:")
print(classification_report(y_test, y_pred_custom))

# Optional: plot ROC curve to visualize threshold trade-offs
fpr, tpr, thresholds = roc_curve(y_test, y_probs)
plt.plot(thresholds, tpr, label="Recall")
plt.plot(thresholds, 1-fpr, label="Specificity")
plt.xlabel("Threshold")
plt.ylabel("Score")
plt.legend()
plt.show()